{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTDgHAD1D3Kw"
   },
   "source": [
    "**Loading and Preprocessing - setting up for cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BKatvt6gD80d"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.datasets import cifar100\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def flatten_data(x_train, y_train, x_test, y_test):\n",
    "    new_image_shape = 1\n",
    "    for dim in range(1, len(x_train.shape)):\n",
    "        new_image_shape *= x_train.shape[dim]\n",
    "        \n",
    "    flat_x_train = x_train.reshape((x_train.shape[0], new_image_shape))\n",
    "    flat_y_train = np.ravel(y_train)\n",
    "    \n",
    "    flat_x_test = x_test.reshape((x_test.shape[0], new_image_shape))\n",
    "    flat_y_test = np.ravel(y_test)\n",
    "    return flat_x_train, flat_y_train, flat_x_test, flat_y_test\n",
    "\n",
    "# centre the data\n",
    "def centre_data(train, test):\n",
    "    \n",
    "    # calculate the means for each attribute of the training data\n",
    "    column_means = np.mean(train, axis=0) \n",
    "    \n",
    "    # centre training data by subtracting training data attribute means\n",
    "    for i in range(len(train)):\n",
    "        train[i] = train[i] - column_means\n",
    "    \n",
    "    # centre testing data by subtracting training data attribute means\n",
    "    for x in range(len(test)):\n",
    "        test[x] = test[x] - column_means\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "# apply PCA on the data \n",
    "def PCA(variance_target, training_data, testing_data):\n",
    "\n",
    "    U, sigma, Vt = np.linalg.svd(training_data, full_matrices=False)\n",
    "    \n",
    "    sum_square_singular = np.sum(sigma**2)\n",
    "    \n",
    "    ratios = sigma**2/sum_square_singular\n",
    "    n_components = 0\n",
    "    explained_variance = 0\n",
    "    \n",
    "    # determine how many principle components must be retained to maintain the target level of explained variance\n",
    "    for i in range(len(ratios)):\n",
    "        if explained_variance >= variance_target:\n",
    "            break\n",
    "        else: \n",
    "            n_components += 1\n",
    "            explained_variance += ratios[i]\n",
    "    \n",
    "    return training_data.dot(Vt.T[:, :n_components]), testing_data.dot(Vt.T[:, :n_components])\n",
    "\n",
    "\n",
    "\n",
    "def load_in_dataset_and_preprocess(explained_variance, training_data, testing_data, training_labels,testing_labels):\n",
    "\n",
    "    concatenated_training = concatenate_data(training_data, training_labels)\n",
    "\n",
    "    training_set, validation_set = split_into_validation_training(concatenated_training)\n",
    "\n",
    "    training_data = training_set[:, :-1]\n",
    "    training_labels = np.squeeze(training_set[:, -1])\n",
    "\n",
    "    validation_data = validation_set[:, :-1]\n",
    "    validation_labels = np.squeeze(validation_set[:, -1])\n",
    "\n",
    "    training_data = training_data.astype('float32')\n",
    "    testing_data = testing_data.astype('float32')\n",
    "    validation_data = validation_data.astype('float32')\n",
    "\n",
    "    # Centre data\n",
    "    #training_data, testing_data, validation_data = centre_data(training_data, testing_data, validation_data)\n",
    "\n",
    "    # Apply PCA\n",
    "    #training_data, testing_data, validation_data = PCA(explained_variance, training_data, testing_data, validation_data)\n",
    "\n",
    "    number_training_samples = len(training_data)\n",
    "    number_validation_samples = len(validation_data)\n",
    "    number_testing_samples = len(testing_data)\n",
    "\n",
    "    # Reshape data from channel to rows\n",
    "    training_data = np.reshape(training_data, (number_training_samples, -1))\n",
    "    validation_data = np.reshape(validation_data, (number_validation_samples, -1))\n",
    "    testing_data = np.reshape(testing_data, (number_testing_samples, -1))\n",
    "\n",
    "    return training_data, training_labels, testing_data, testing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g72E1OmgD9XB"
   },
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUu4JuHSEAFQ",
    "outputId": "eeebf323-1d17-448d-94f7-2c47009d2889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  34.91428571428571\n",
      "accuracy:  32.74285714285714\n",
      "accuracy:  28.142857142857142\n",
      "accuracy:  24.942857142857143\n",
      "accuracy:  24.257142857142856\n",
      "accuracy:  22.8\n",
      "accuracy:  20.82857142857143\n",
      "accuracy:  21.02857142857143\n",
      "accuracy:  22.142857142857142\n",
      "accuracy:  21.428571428571427\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from keras.datasets import cifar100\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class SVM:\n",
    "\n",
    "    training_data=[]\n",
    "    testing_data=[]\n",
    "\n",
    "    def __init__(self, training_data, testing_data):\n",
    "      self.training_data= training_data\n",
    "      self.testing_data= testing_data\n",
    "\n",
    "    def __len__(self, data):\n",
    "      return len(data)\n",
    "\n",
    "    def calculate_linear_output(self, data, weights):\n",
    "      return np.dot(data, weights)\n",
    "\n",
    "    # distance of point from separating hyperplane?\n",
    "    def calculate_distance(self, X, w):\n",
    "      return  y * (np.dot(X, w)) - 1\n",
    "\n",
    "    # calculate gradient, use L2 regularisation \n",
    "    def calculate_gradient(self, weights, regularisation_param, training_data, training_labels, num_classes):\n",
    "        \n",
    "        num_training_samples, num_training_features = training_data.shape\n",
    "        \n",
    "        gradient = np.zeros((num_training_features, num_classes))\n",
    "        \n",
    "        # w^Tx\n",
    "        linear_output = self.calculate_linear_output(training_data, weights)\n",
    "\n",
    "        #linear output with labels \n",
    "        linear_output_y_i = linear_output[np.arange(num_training_samples),training_labels]\n",
    "        delta = linear_output - linear_output_y_i[:,np.newaxis] + 1\n",
    "        \n",
    "        ones_and_zeros = np.zeros(delta.shape)\n",
    "        \n",
    "        # makes all the places where delta > 0, 1 else 0\n",
    "        # With lagrange multiplier considered, if the sample is on the support vector: ð›¼ = 1\n",
    "        # else: ð›¼ = 0\n",
    "        ones_and_zeros = np.where(delta > 0, 1, 0)\n",
    "        \n",
    "        # calculate the sum of each row \n",
    "        sum_of_each_row = np.sum(ones_and_zeros, axis=1)\n",
    "        \n",
    "        ones_and_zeros[np.arange(num_training_samples), training_labels] = - sum_of_each_row\n",
    "\n",
    "        gradient = (1/num_training_samples) * np.dot((training_data.T), ones_and_zeros)\n",
    "        \n",
    "        # controls the influence of each individual support vector on the objective function. \n",
    "        # Greater C decreases the effect of |w|Â²/2, and results in the narrower margin\n",
    "        gradient = gradient + (2* regularisation_param * weights)\n",
    "        \n",
    "        return gradient \n",
    "\n",
    "    # train model using stochastic gradient descent \n",
    "    def train_model(self, training_data, training_labels, weights, learning_rate, regularisation_param, iterations, batch_size, num_classes):\n",
    "      \n",
    "      num_training_samples = len(training_data)\n",
    "      weights = weights\n",
    "\n",
    "      for i in range(iterations):\n",
    "      # create batch\n",
    "          batch = np.random.choice(5000, batch_size) #change this to num_training_samples \n",
    "          gradient = self.calculate_gradient(weights, regularisation_param, training_data[batch], training_labels[batch], num_classes)\n",
    "          weights = weights - learning_rate * gradient\n",
    "\n",
    "      return weights\n",
    "\n",
    "    # calculate accuracy of model \n",
    "    def calculate_accuracy (self, data, labels, weights):\n",
    "        \n",
    "        accuracy = 0\n",
    "        prediction = np.zeros(len(data))\n",
    "\n",
    "      #w^Tx\n",
    "        linear_output= self.calculate_linear_output(data, weights)\n",
    "\n",
    "      # returns the indices of the maximum values along an axis, ie. in this case will return the \n",
    "      # column index corresponding to the greatest index of each row\n",
    "        prediction = np.argmax(linear_output, axis=1)\n",
    "\n",
    "      # count the number of predictions that are correct \n",
    "        total_correct_predictions = (prediction == labels).sum()\n",
    "        num_data_points = len(data)\n",
    "        accuracy = (total_correct_predictions/num_data_points)*100\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "# helper function for concatenating labels onto their corresponding data points\n",
    "def concatenate_data(training_data, training_labels):\n",
    "    return np.column_stack((training_data, training_labels))\n",
    "\n",
    "# data set is randomised and then split in a 70:30 ratio for training:validation sets\n",
    "def split_into_validation_training(training_matrix):\n",
    "    \n",
    "    import random\n",
    "    random.shuffle(training_matrix)\n",
    "\n",
    "    training_set = training_matrix[:int(len(training_matrix)*0.7)]\n",
    "    validation_set = training_matrix[int(len(training_matrix)*0.7):]\n",
    "    \n",
    "    return training_set, validation_set\n",
    "\n",
    "#using 10 fold cross validation here to evaluate the performance of SVM\n",
    "def cross_validation():\n",
    "\n",
    "  (training_data, training_labels), (testing_data, testing_labels) = (cifar100.load_data(\"coarse\"))\n",
    "\n",
    "  # reshape the data \n",
    "  training_data = training_data.reshape(50000, 3072)\n",
    "  testing_data = testing_data.reshape(10000, 3072)\n",
    "  \n",
    "  concatenated_training = concatenate_data(training_data, training_labels)\n",
    "\n",
    "  training_set, validation_set = split_into_validation_training(concatenated_training)\n",
    "\n",
    "  training_data = training_set[:, :-1]\n",
    "  training_labels = np.squeeze(training_set[:, -1])\n",
    "\n",
    "  validation_data = validation_set[:, :-1]\n",
    "  validation_labels = np.squeeze(validation_set[:, -1])\n",
    "\n",
    "  training_data = training_data.astype('float32')\n",
    "  testing_data = testing_data.astype('float32')\n",
    "  validation_data = validation_data.astype('float32')\n",
    "\n",
    "  # Centre data\n",
    "  #training_data, testing_data, validation_data = centre_data(training_data, testing_data, validation_data)\n",
    "\n",
    "  # Apply PCA\n",
    "  #training_data, testing_data, validation_data = PCA(explained_variance, training_data, testing_data, validation_data)\n",
    "\n",
    "  number_training_samples = len(training_data)\n",
    "  number_validation_samples = len(validation_data)\n",
    "  number_testing_samples = len(testing_data)\n",
    "\n",
    "  # Reshape data from channel to rows\n",
    "  training_data = np.reshape(training_data, (number_training_samples, -1))\n",
    "  validation_data = np.reshape(validation_data, (number_validation_samples, -1))\n",
    "  testing_data = np.reshape(testing_data, (number_testing_samples, -1))\n",
    "\n",
    "  #training_data, training_labels, testing_data, testing_labels = load_in_dataset_and_preprocess(0.9, training_data, training_labels, testing_data, testing_labels)\n",
    "  \n",
    "  cv = KFold(n_splits=10)\n",
    "\n",
    "  for train_index, test_index in cv.split(training_data):\n",
    "\n",
    "    training_set, training_set_labels = training_data[train_index], training_labels[train_index]\n",
    "    testing_set, testing_set_labels = training_data[test_index], training_labels[test_index]\n",
    "\n",
    "    svm = SVM(training_set, testing_set)\n",
    "    num_classes = np.max(training_set_labels) + 1\n",
    "    weights = np.ones((len(training_set[1]), num_classes))\n",
    "    weights= svm.train_model(training_set, training_set_labels, weights, 0.00000001, 1000, 20000, 200, 20)\n",
    "\n",
    "    total_accuracy = svm.calculate_accuracy(testing_set, testing_set_labels, weights)\n",
    "    print('accuracy: ', total_accuracy)\n",
    "\n",
    "cross_validation()\n",
    "\n",
    "  #run the classifiers here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv6hAGTTEAY5"
   },
   "source": [
    "**Multi-Layer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kU525n67EC6W",
    "outputId": "23a7a9af-31dd-40e7-c580-eb91f33c6e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7495 - accuracy: 0.1687 - val_loss: 2.4587 - val_accuracy: 0.2524\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4821 - accuracy: 0.2325 - val_loss: 2.3327 - val_accuracy: 0.2944\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3738 - accuracy: 0.2675 - val_loss: 2.2599 - val_accuracy: 0.3106\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2947 - accuracy: 0.2918 - val_loss: 2.2189 - val_accuracy: 0.3170\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2492 - accuracy: 0.3014 - val_loss: 2.1717 - val_accuracy: 0.3322\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.2015 - accuracy: 0.3136 - val_loss: 2.1515 - val_accuracy: 0.3517\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1646 - accuracy: 0.3279 - val_loss: 2.1267 - val_accuracy: 0.3638\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.1316 - accuracy: 0.3365 - val_loss: 2.1082 - val_accuracy: 0.3670\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0995 - accuracy: 0.3432 - val_loss: 2.0820 - val_accuracy: 0.3730\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0729 - accuracy: 0.3553 - val_loss: 2.0556 - val_accuracy: 0.3846\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 2.0433 - accuracy: 0.3612 - val_loss: 2.0487 - val_accuracy: 0.3917\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 2.0263 - accuracy: 0.3702 - val_loss: 2.0301 - val_accuracy: 0.3916\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9931 - accuracy: 0.3792 - val_loss: 2.0177 - val_accuracy: 0.3929\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9815 - accuracy: 0.3805 - val_loss: 2.0015 - val_accuracy: 0.4022\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9625 - accuracy: 0.3894 - val_loss: 1.9934 - val_accuracy: 0.3975\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.9504 - accuracy: 0.3941 - val_loss: 1.9751 - val_accuracy: 0.4102\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.9305 - accuracy: 0.3973 - val_loss: 1.9824 - val_accuracy: 0.4103\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.9169 - accuracy: 0.4006 - val_loss: 1.9656 - val_accuracy: 0.4151\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8998 - accuracy: 0.4078 - val_loss: 1.9617 - val_accuracy: 0.4186\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8902 - accuracy: 0.4060 - val_loss: 1.9523 - val_accuracy: 0.4192\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8744 - accuracy: 0.4157 - val_loss: 1.9341 - val_accuracy: 0.4252\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8662 - accuracy: 0.4135 - val_loss: 1.9298 - val_accuracy: 0.4267\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.8535 - accuracy: 0.4217 - val_loss: 1.9291 - val_accuracy: 0.4306\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.8473 - accuracy: 0.4240 - val_loss: 1.9232 - val_accuracy: 0.4268\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.8419 - accuracy: 0.4263 - val_loss: 1.9190 - val_accuracy: 0.4263\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.8324 - accuracy: 0.4304 - val_loss: 1.9098 - val_accuracy: 0.4311\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.8264 - accuracy: 0.4310 - val_loss: 1.9080 - val_accuracy: 0.4349\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.8151 - accuracy: 0.4338 - val_loss: 1.9035 - val_accuracy: 0.4344\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.8050 - accuracy: 0.4330 - val_loss: 1.9012 - val_accuracy: 0.4419\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.8036 - accuracy: 0.4389 - val_loss: 1.8855 - val_accuracy: 0.4427\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.8002 - accuracy: 0.4362 - val_loss: 1.8842 - val_accuracy: 0.4414\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7847 - accuracy: 0.4438 - val_loss: 1.8911 - val_accuracy: 0.4443\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7784 - accuracy: 0.4447 - val_loss: 1.8726 - val_accuracy: 0.4471\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7788 - accuracy: 0.4433 - val_loss: 1.8804 - val_accuracy: 0.4413\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.7731 - accuracy: 0.4463 - val_loss: 1.8780 - val_accuracy: 0.4387\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.7561 - accuracy: 0.4513 - val_loss: 1.8636 - val_accuracy: 0.4470\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.7697 - accuracy: 0.4491 - val_loss: 1.8762 - val_accuracy: 0.4438\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.7535 - accuracy: 0.4516 - val_loss: 1.8642 - val_accuracy: 0.4430\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.7534 - accuracy: 0.4552 - val_loss: 1.8656 - val_accuracy: 0.4476\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.7493 - accuracy: 0.4506 - val_loss: 1.8590 - val_accuracy: 0.4494\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.7380 - accuracy: 0.4588 - val_loss: 1.8475 - val_accuracy: 0.4510\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.7432 - accuracy: 0.4541 - val_loss: 1.8653 - val_accuracy: 0.4452\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.7307 - accuracy: 0.4615 - val_loss: 1.8552 - val_accuracy: 0.4500\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.7252 - accuracy: 0.4599 - val_loss: 1.8545 - val_accuracy: 0.4510\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.7236 - accuracy: 0.4652 - val_loss: 1.8641 - val_accuracy: 0.4487\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.7320 - accuracy: 0.4644 - val_loss: 1.8551 - val_accuracy: 0.4498\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.7171 - accuracy: 0.4667 - val_loss: 1.8551 - val_accuracy: 0.4543\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.7055 - accuracy: 0.4702 - val_loss: 1.8486 - val_accuracy: 0.4597\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.7142 - accuracy: 0.4649 - val_loss: 1.8519 - val_accuracy: 0.4503\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6994 - accuracy: 0.4742 - val_loss: 1.8469 - val_accuracy: 0.4595\n",
      "accuracy:  0.6694285869598389\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7554 - accuracy: 0.1642 - val_loss: 2.4530 - val_accuracy: 0.2548\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4807 - accuracy: 0.2375 - val_loss: 2.3533 - val_accuracy: 0.2837\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3641 - accuracy: 0.2696 - val_loss: 2.2673 - val_accuracy: 0.3121\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2965 - accuracy: 0.2923 - val_loss: 2.2398 - val_accuracy: 0.3213\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2370 - accuracy: 0.3074 - val_loss: 2.1817 - val_accuracy: 0.3367\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1802 - accuracy: 0.3282 - val_loss: 2.1589 - val_accuracy: 0.3475\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1503 - accuracy: 0.3342 - val_loss: 2.1400 - val_accuracy: 0.3503\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.1191 - accuracy: 0.3417 - val_loss: 2.1211 - val_accuracy: 0.3635\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0861 - accuracy: 0.3530 - val_loss: 2.0950 - val_accuracy: 0.3667\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0492 - accuracy: 0.3675 - val_loss: 2.0616 - val_accuracy: 0.3824\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 2.0307 - accuracy: 0.3740 - val_loss: 2.0522 - val_accuracy: 0.3771\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 2.0021 - accuracy: 0.3741 - val_loss: 2.0373 - val_accuracy: 0.3870\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9773 - accuracy: 0.3874 - val_loss: 2.0163 - val_accuracy: 0.3935\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9646 - accuracy: 0.3913 - val_loss: 2.0133 - val_accuracy: 0.3910\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9364 - accuracy: 0.4002 - val_loss: 1.9905 - val_accuracy: 0.3924\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.9237 - accuracy: 0.4013 - val_loss: 1.9863 - val_accuracy: 0.4033\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.9033 - accuracy: 0.4066 - val_loss: 1.9744 - val_accuracy: 0.4056\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8969 - accuracy: 0.4132 - val_loss: 1.9658 - val_accuracy: 0.3997\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8797 - accuracy: 0.4142 - val_loss: 1.9694 - val_accuracy: 0.4060\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8706 - accuracy: 0.4221 - val_loss: 1.9595 - val_accuracy: 0.4067\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8618 - accuracy: 0.4204 - val_loss: 1.9526 - val_accuracy: 0.4076\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8375 - accuracy: 0.4282 - val_loss: 1.9588 - val_accuracy: 0.4033\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.8262 - accuracy: 0.4273 - val_loss: 1.9357 - val_accuracy: 0.4186\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.8317 - accuracy: 0.4335 - val_loss: 1.9317 - val_accuracy: 0.4162\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.8168 - accuracy: 0.4342 - val_loss: 1.9291 - val_accuracy: 0.4262\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.8157 - accuracy: 0.4357 - val_loss: 1.9241 - val_accuracy: 0.4233\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7965 - accuracy: 0.4405 - val_loss: 1.9203 - val_accuracy: 0.4229\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7945 - accuracy: 0.4406 - val_loss: 1.9183 - val_accuracy: 0.4267\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7758 - accuracy: 0.4466 - val_loss: 1.9109 - val_accuracy: 0.4297\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7807 - accuracy: 0.4450 - val_loss: 1.9068 - val_accuracy: 0.4310\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7658 - accuracy: 0.4484 - val_loss: 1.9021 - val_accuracy: 0.4327\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7648 - accuracy: 0.4544 - val_loss: 1.9088 - val_accuracy: 0.4284\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7742 - accuracy: 0.4494 - val_loss: 1.9077 - val_accuracy: 0.4257\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7321 - accuracy: 0.4652 - val_loss: 1.8922 - val_accuracy: 0.4246\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.7427 - accuracy: 0.4613 - val_loss: 1.8891 - val_accuracy: 0.4302\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.7444 - accuracy: 0.4611 - val_loss: 1.8961 - val_accuracy: 0.4360\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.7331 - accuracy: 0.4604 - val_loss: 1.9017 - val_accuracy: 0.4344\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.7297 - accuracy: 0.4598 - val_loss: 1.8949 - val_accuracy: 0.4397\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.7269 - accuracy: 0.4665 - val_loss: 1.8940 - val_accuracy: 0.4421\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.7195 - accuracy: 0.4680 - val_loss: 1.8944 - val_accuracy: 0.4368\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.7206 - accuracy: 0.4649 - val_loss: 1.8848 - val_accuracy: 0.4314\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.7025 - accuracy: 0.4730 - val_loss: 1.8911 - val_accuracy: 0.4322\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.7088 - accuracy: 0.4688 - val_loss: 1.8862 - val_accuracy: 0.4395\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.7038 - accuracy: 0.4723 - val_loss: 1.8827 - val_accuracy: 0.4360\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6997 - accuracy: 0.4781 - val_loss: 1.8799 - val_accuracy: 0.4316\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6899 - accuracy: 0.4726 - val_loss: 1.8786 - val_accuracy: 0.4371\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6918 - accuracy: 0.4757 - val_loss: 1.8728 - val_accuracy: 0.4408\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6943 - accuracy: 0.4733 - val_loss: 1.8898 - val_accuracy: 0.4370\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6774 - accuracy: 0.4775 - val_loss: 1.8709 - val_accuracy: 0.4497\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6756 - accuracy: 0.4801 - val_loss: 1.8849 - val_accuracy: 0.4405\n",
      "accuracy:  0.6365714073181152\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7523 - accuracy: 0.1644 - val_loss: 2.4721 - val_accuracy: 0.2597\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4738 - accuracy: 0.2426 - val_loss: 2.3584 - val_accuracy: 0.2943\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3609 - accuracy: 0.2761 - val_loss: 2.2740 - val_accuracy: 0.3081\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2890 - accuracy: 0.2887 - val_loss: 2.2269 - val_accuracy: 0.3335\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2325 - accuracy: 0.3128 - val_loss: 2.1854 - val_accuracy: 0.3400\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1749 - accuracy: 0.3262 - val_loss: 2.1531 - val_accuracy: 0.3476\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1430 - accuracy: 0.3339 - val_loss: 2.1319 - val_accuracy: 0.3592\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.1042 - accuracy: 0.3451 - val_loss: 2.1081 - val_accuracy: 0.3644\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0668 - accuracy: 0.3581 - val_loss: 2.0750 - val_accuracy: 0.3722\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0452 - accuracy: 0.3652 - val_loss: 2.0645 - val_accuracy: 0.3811\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 2.0192 - accuracy: 0.3756 - val_loss: 2.0518 - val_accuracy: 0.3854\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9973 - accuracy: 0.3815 - val_loss: 2.0274 - val_accuracy: 0.3914\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9657 - accuracy: 0.3884 - val_loss: 2.0195 - val_accuracy: 0.3887\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9506 - accuracy: 0.3912 - val_loss: 1.9979 - val_accuracy: 0.3959\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9356 - accuracy: 0.3974 - val_loss: 2.0015 - val_accuracy: 0.3967\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.9130 - accuracy: 0.4069 - val_loss: 1.9948 - val_accuracy: 0.4095\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.9094 - accuracy: 0.4057 - val_loss: 1.9976 - val_accuracy: 0.4078\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8951 - accuracy: 0.4107 - val_loss: 1.9807 - val_accuracy: 0.4086\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8650 - accuracy: 0.4205 - val_loss: 1.9691 - val_accuracy: 0.4110\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8568 - accuracy: 0.4218 - val_loss: 1.9556 - val_accuracy: 0.4175\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8444 - accuracy: 0.4246 - val_loss: 1.9498 - val_accuracy: 0.4178\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8339 - accuracy: 0.4284 - val_loss: 1.9368 - val_accuracy: 0.4286\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.8301 - accuracy: 0.4309 - val_loss: 1.9372 - val_accuracy: 0.4281\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.8216 - accuracy: 0.4348 - val_loss: 1.9425 - val_accuracy: 0.4316\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.8066 - accuracy: 0.4377 - val_loss: 1.9262 - val_accuracy: 0.4324\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7970 - accuracy: 0.4445 - val_loss: 1.9215 - val_accuracy: 0.4363\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7895 - accuracy: 0.4413 - val_loss: 1.9150 - val_accuracy: 0.4338\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7728 - accuracy: 0.4475 - val_loss: 1.9076 - val_accuracy: 0.4427\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7678 - accuracy: 0.4479 - val_loss: 1.9089 - val_accuracy: 0.4387\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7678 - accuracy: 0.4514 - val_loss: 1.8972 - val_accuracy: 0.4398\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7629 - accuracy: 0.4554 - val_loss: 1.9123 - val_accuracy: 0.4359\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7546 - accuracy: 0.4554 - val_loss: 1.8976 - val_accuracy: 0.4375\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7537 - accuracy: 0.4563 - val_loss: 1.8978 - val_accuracy: 0.4432\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7429 - accuracy: 0.4536 - val_loss: 1.8997 - val_accuracy: 0.4386\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.7331 - accuracy: 0.4621 - val_loss: 1.8904 - val_accuracy: 0.4497\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.7296 - accuracy: 0.4598 - val_loss: 1.9027 - val_accuracy: 0.4444\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.7208 - accuracy: 0.4709 - val_loss: 1.8891 - val_accuracy: 0.4448\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.7139 - accuracy: 0.4692 - val_loss: 1.8928 - val_accuracy: 0.4476\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.7064 - accuracy: 0.4715 - val_loss: 1.8893 - val_accuracy: 0.4521\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.7104 - accuracy: 0.4685 - val_loss: 1.8823 - val_accuracy: 0.4506\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6855 - accuracy: 0.4752 - val_loss: 1.8864 - val_accuracy: 0.4438\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6959 - accuracy: 0.4740 - val_loss: 1.8822 - val_accuracy: 0.4463\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6880 - accuracy: 0.4750 - val_loss: 1.8819 - val_accuracy: 0.4468\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6845 - accuracy: 0.4790 - val_loss: 1.8814 - val_accuracy: 0.4486\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6775 - accuracy: 0.4781 - val_loss: 1.8784 - val_accuracy: 0.4454\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6797 - accuracy: 0.4802 - val_loss: 1.8683 - val_accuracy: 0.4486\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6682 - accuracy: 0.4841 - val_loss: 1.8808 - val_accuracy: 0.4483\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6757 - accuracy: 0.4806 - val_loss: 1.8839 - val_accuracy: 0.4444\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6677 - accuracy: 0.4815 - val_loss: 1.8681 - val_accuracy: 0.4508\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6761 - accuracy: 0.4792 - val_loss: 1.8679 - val_accuracy: 0.4568\n",
      "accuracy:  0.6140000224113464\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7459 - accuracy: 0.1696 - val_loss: 2.4550 - val_accuracy: 0.2590\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4642 - accuracy: 0.2433 - val_loss: 2.3277 - val_accuracy: 0.2951\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3510 - accuracy: 0.2769 - val_loss: 2.2742 - val_accuracy: 0.3162\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2744 - accuracy: 0.3007 - val_loss: 2.2115 - val_accuracy: 0.3259\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2300 - accuracy: 0.3110 - val_loss: 2.1743 - val_accuracy: 0.3381\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1739 - accuracy: 0.3256 - val_loss: 2.1477 - val_accuracy: 0.3505\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1215 - accuracy: 0.3396 - val_loss: 2.1274 - val_accuracy: 0.3551\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0881 - accuracy: 0.3530 - val_loss: 2.1030 - val_accuracy: 0.3670\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0543 - accuracy: 0.3625 - val_loss: 2.0849 - val_accuracy: 0.3741\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0276 - accuracy: 0.3696 - val_loss: 2.0481 - val_accuracy: 0.3875\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9957 - accuracy: 0.3824 - val_loss: 2.0397 - val_accuracy: 0.3779\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9718 - accuracy: 0.3874 - val_loss: 2.0394 - val_accuracy: 0.3902\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9659 - accuracy: 0.3915 - val_loss: 2.0240 - val_accuracy: 0.3937\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9300 - accuracy: 0.3973 - val_loss: 1.9965 - val_accuracy: 0.3986\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9007 - accuracy: 0.4094 - val_loss: 1.9886 - val_accuracy: 0.3983\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8902 - accuracy: 0.4137 - val_loss: 1.9838 - val_accuracy: 0.4040\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8852 - accuracy: 0.4181 - val_loss: 1.9688 - val_accuracy: 0.4125\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8575 - accuracy: 0.4187 - val_loss: 1.9780 - val_accuracy: 0.4081\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8454 - accuracy: 0.4266 - val_loss: 1.9568 - val_accuracy: 0.4189\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8311 - accuracy: 0.4325 - val_loss: 1.9500 - val_accuracy: 0.4152\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8189 - accuracy: 0.4337 - val_loss: 1.9471 - val_accuracy: 0.4256\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8091 - accuracy: 0.4379 - val_loss: 1.9345 - val_accuracy: 0.4222\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.8009 - accuracy: 0.4427 - val_loss: 1.9333 - val_accuracy: 0.4262\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7984 - accuracy: 0.4437 - val_loss: 1.9412 - val_accuracy: 0.4119\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7811 - accuracy: 0.4484 - val_loss: 1.9323 - val_accuracy: 0.4176\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7839 - accuracy: 0.4450 - val_loss: 1.9258 - val_accuracy: 0.4275\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7629 - accuracy: 0.4556 - val_loss: 1.9145 - val_accuracy: 0.4298\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7503 - accuracy: 0.4552 - val_loss: 1.9131 - val_accuracy: 0.4351\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7486 - accuracy: 0.4592 - val_loss: 1.9068 - val_accuracy: 0.4316\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7381 - accuracy: 0.4650 - val_loss: 1.9174 - val_accuracy: 0.4319\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7294 - accuracy: 0.4690 - val_loss: 1.9141 - val_accuracy: 0.4305\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7138 - accuracy: 0.4678 - val_loss: 1.9081 - val_accuracy: 0.4303\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7244 - accuracy: 0.4645 - val_loss: 1.9024 - val_accuracy: 0.4322\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7080 - accuracy: 0.4685 - val_loss: 1.8945 - val_accuracy: 0.4351\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.7063 - accuracy: 0.4691 - val_loss: 1.8966 - val_accuracy: 0.4349\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.7081 - accuracy: 0.4698 - val_loss: 1.8854 - val_accuracy: 0.4375\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6942 - accuracy: 0.4765 - val_loss: 1.8873 - val_accuracy: 0.4378\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6841 - accuracy: 0.4751 - val_loss: 1.8796 - val_accuracy: 0.4421\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6983 - accuracy: 0.4737 - val_loss: 1.8941 - val_accuracy: 0.4337\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6740 - accuracy: 0.4838 - val_loss: 1.8798 - val_accuracy: 0.4410\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6873 - accuracy: 0.4787 - val_loss: 1.8731 - val_accuracy: 0.4451\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6702 - accuracy: 0.4819 - val_loss: 1.8791 - val_accuracy: 0.4429\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6802 - accuracy: 0.4796 - val_loss: 1.8839 - val_accuracy: 0.4432\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6644 - accuracy: 0.4863 - val_loss: 1.8828 - val_accuracy: 0.4443\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6498 - accuracy: 0.4916 - val_loss: 1.8816 - val_accuracy: 0.4422\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6579 - accuracy: 0.4858 - val_loss: 1.8648 - val_accuracy: 0.4530\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6461 - accuracy: 0.4898 - val_loss: 1.8714 - val_accuracy: 0.4522\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6475 - accuracy: 0.4895 - val_loss: 1.8700 - val_accuracy: 0.4416\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6352 - accuracy: 0.4923 - val_loss: 1.8763 - val_accuracy: 0.4429\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6374 - accuracy: 0.4925 - val_loss: 1.8722 - val_accuracy: 0.4451\n",
      "accuracy:  0.5628571510314941\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7428 - accuracy: 0.1653 - val_loss: 2.4677 - val_accuracy: 0.2478\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4707 - accuracy: 0.2410 - val_loss: 2.3465 - val_accuracy: 0.2878\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3611 - accuracy: 0.2692 - val_loss: 2.2815 - val_accuracy: 0.3073\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2746 - accuracy: 0.2960 - val_loss: 2.2179 - val_accuracy: 0.3233\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2037 - accuracy: 0.3192 - val_loss: 2.1829 - val_accuracy: 0.3394\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1656 - accuracy: 0.3281 - val_loss: 2.1573 - val_accuracy: 0.3437\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1230 - accuracy: 0.3409 - val_loss: 2.1236 - val_accuracy: 0.3519\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0806 - accuracy: 0.3540 - val_loss: 2.0980 - val_accuracy: 0.3595\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0533 - accuracy: 0.3596 - val_loss: 2.0931 - val_accuracy: 0.3717\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0121 - accuracy: 0.3692 - val_loss: 2.0731 - val_accuracy: 0.3775\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9978 - accuracy: 0.3792 - val_loss: 2.0477 - val_accuracy: 0.3835\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9678 - accuracy: 0.3867 - val_loss: 2.0345 - val_accuracy: 0.3892\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9388 - accuracy: 0.3976 - val_loss: 2.0165 - val_accuracy: 0.3978\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9180 - accuracy: 0.4050 - val_loss: 2.0067 - val_accuracy: 0.3952\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9063 - accuracy: 0.4107 - val_loss: 2.0005 - val_accuracy: 0.3989\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8778 - accuracy: 0.4182 - val_loss: 1.9982 - val_accuracy: 0.3994\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8699 - accuracy: 0.4184 - val_loss: 1.9830 - val_accuracy: 0.4089\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8629 - accuracy: 0.4251 - val_loss: 1.9819 - val_accuracy: 0.4135\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8329 - accuracy: 0.4275 - val_loss: 1.9788 - val_accuracy: 0.4149\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8293 - accuracy: 0.4356 - val_loss: 1.9708 - val_accuracy: 0.4133\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8188 - accuracy: 0.4386 - val_loss: 1.9674 - val_accuracy: 0.4165\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8005 - accuracy: 0.4424 - val_loss: 1.9588 - val_accuracy: 0.4205\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7885 - accuracy: 0.4452 - val_loss: 1.9477 - val_accuracy: 0.4257\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7761 - accuracy: 0.4492 - val_loss: 1.9483 - val_accuracy: 0.4224\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7758 - accuracy: 0.4502 - val_loss: 1.9447 - val_accuracy: 0.4271\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7657 - accuracy: 0.4515 - val_loss: 1.9483 - val_accuracy: 0.4230\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7597 - accuracy: 0.4544 - val_loss: 1.9245 - val_accuracy: 0.4287\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7403 - accuracy: 0.4624 - val_loss: 1.9364 - val_accuracy: 0.4303\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7388 - accuracy: 0.4615 - val_loss: 1.9280 - val_accuracy: 0.4321\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7350 - accuracy: 0.4627 - val_loss: 1.9190 - val_accuracy: 0.4278\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7238 - accuracy: 0.4669 - val_loss: 1.9108 - val_accuracy: 0.4349\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7092 - accuracy: 0.4709 - val_loss: 1.9116 - val_accuracy: 0.4305\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7077 - accuracy: 0.4699 - val_loss: 1.9133 - val_accuracy: 0.4344\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7092 - accuracy: 0.4715 - val_loss: 1.9089 - val_accuracy: 0.4375\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.6951 - accuracy: 0.4749 - val_loss: 1.9064 - val_accuracy: 0.4463\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.6824 - accuracy: 0.4788 - val_loss: 1.9074 - val_accuracy: 0.4405\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6777 - accuracy: 0.4814 - val_loss: 1.8975 - val_accuracy: 0.4411\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6930 - accuracy: 0.4775 - val_loss: 1.9021 - val_accuracy: 0.4410\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6816 - accuracy: 0.4777 - val_loss: 1.8917 - val_accuracy: 0.4478\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6754 - accuracy: 0.4806 - val_loss: 1.8871 - val_accuracy: 0.4475\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6651 - accuracy: 0.4845 - val_loss: 1.8798 - val_accuracy: 0.4524\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6633 - accuracy: 0.4837 - val_loss: 1.8825 - val_accuracy: 0.4473\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6711 - accuracy: 0.4875 - val_loss: 1.8811 - val_accuracy: 0.4452\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6529 - accuracy: 0.4905 - val_loss: 1.8757 - val_accuracy: 0.4467\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6427 - accuracy: 0.4928 - val_loss: 1.8838 - val_accuracy: 0.4548\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6524 - accuracy: 0.4897 - val_loss: 1.8863 - val_accuracy: 0.4508\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6414 - accuracy: 0.4912 - val_loss: 1.8759 - val_accuracy: 0.4517\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6342 - accuracy: 0.4946 - val_loss: 1.8764 - val_accuracy: 0.4570\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6431 - accuracy: 0.4951 - val_loss: 1.8813 - val_accuracy: 0.4548\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6212 - accuracy: 0.5000 - val_loss: 1.8695 - val_accuracy: 0.4510\n",
      "accuracy:  0.524571418762207\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7476 - accuracy: 0.1655 - val_loss: 2.4554 - val_accuracy: 0.2505\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4692 - accuracy: 0.2381 - val_loss: 2.3373 - val_accuracy: 0.2821\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3532 - accuracy: 0.2761 - val_loss: 2.2849 - val_accuracy: 0.3116\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2736 - accuracy: 0.2984 - val_loss: 2.2120 - val_accuracy: 0.3362\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2147 - accuracy: 0.3165 - val_loss: 2.1882 - val_accuracy: 0.3390\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1632 - accuracy: 0.3317 - val_loss: 2.1526 - val_accuracy: 0.3524\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1178 - accuracy: 0.3462 - val_loss: 2.1312 - val_accuracy: 0.3544\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0843 - accuracy: 0.3547 - val_loss: 2.1027 - val_accuracy: 0.3603\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0422 - accuracy: 0.3664 - val_loss: 2.1045 - val_accuracy: 0.3683\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0163 - accuracy: 0.3773 - val_loss: 2.0718 - val_accuracy: 0.3762\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9855 - accuracy: 0.3869 - val_loss: 2.0579 - val_accuracy: 0.3760\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9700 - accuracy: 0.3879 - val_loss: 2.0277 - val_accuracy: 0.3848\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9448 - accuracy: 0.3979 - val_loss: 2.0240 - val_accuracy: 0.3970\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9121 - accuracy: 0.4076 - val_loss: 2.0112 - val_accuracy: 0.3933\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.9128 - accuracy: 0.4075 - val_loss: 2.0065 - val_accuracy: 0.3910\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8786 - accuracy: 0.4184 - val_loss: 1.9901 - val_accuracy: 0.3995\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8681 - accuracy: 0.4221 - val_loss: 1.9710 - val_accuracy: 0.4054\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8538 - accuracy: 0.4213 - val_loss: 1.9683 - val_accuracy: 0.4084\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8451 - accuracy: 0.4275 - val_loss: 1.9610 - val_accuracy: 0.4114\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8367 - accuracy: 0.4328 - val_loss: 1.9559 - val_accuracy: 0.4078\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8152 - accuracy: 0.4348 - val_loss: 1.9474 - val_accuracy: 0.4122\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.8075 - accuracy: 0.4417 - val_loss: 1.9373 - val_accuracy: 0.4110\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7931 - accuracy: 0.4401 - val_loss: 1.9419 - val_accuracy: 0.4137\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7858 - accuracy: 0.4476 - val_loss: 1.9435 - val_accuracy: 0.4179\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7625 - accuracy: 0.4563 - val_loss: 1.9319 - val_accuracy: 0.4187\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7611 - accuracy: 0.4565 - val_loss: 1.9313 - val_accuracy: 0.4167\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7646 - accuracy: 0.4544 - val_loss: 1.9220 - val_accuracy: 0.4252\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7459 - accuracy: 0.4590 - val_loss: 1.9180 - val_accuracy: 0.4257\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7530 - accuracy: 0.4558 - val_loss: 1.9068 - val_accuracy: 0.4287\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7387 - accuracy: 0.4623 - val_loss: 1.9138 - val_accuracy: 0.4238\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7314 - accuracy: 0.4645 - val_loss: 1.9120 - val_accuracy: 0.4225\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7255 - accuracy: 0.4676 - val_loss: 1.9109 - val_accuracy: 0.4246\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.7143 - accuracy: 0.4661 - val_loss: 1.9012 - val_accuracy: 0.4241\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.7008 - accuracy: 0.4764 - val_loss: 1.9052 - val_accuracy: 0.4356\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.7017 - accuracy: 0.4721 - val_loss: 1.8921 - val_accuracy: 0.4284\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.7023 - accuracy: 0.4714 - val_loss: 1.9002 - val_accuracy: 0.4298\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6873 - accuracy: 0.4742 - val_loss: 1.8829 - val_accuracy: 0.4392\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6949 - accuracy: 0.4798 - val_loss: 1.9026 - val_accuracy: 0.4340\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6792 - accuracy: 0.4832 - val_loss: 1.8856 - val_accuracy: 0.4398\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6830 - accuracy: 0.4771 - val_loss: 1.8908 - val_accuracy: 0.4386\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6659 - accuracy: 0.4877 - val_loss: 1.8937 - val_accuracy: 0.4319\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6635 - accuracy: 0.4827 - val_loss: 1.8926 - val_accuracy: 0.4305\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6544 - accuracy: 0.4886 - val_loss: 1.8744 - val_accuracy: 0.4324\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6566 - accuracy: 0.4908 - val_loss: 1.8800 - val_accuracy: 0.4395\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6536 - accuracy: 0.4905 - val_loss: 1.8755 - val_accuracy: 0.4405\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6445 - accuracy: 0.4929 - val_loss: 1.8895 - val_accuracy: 0.4363\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6476 - accuracy: 0.4923 - val_loss: 1.8858 - val_accuracy: 0.4337\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6425 - accuracy: 0.4914 - val_loss: 1.8717 - val_accuracy: 0.4422\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6335 - accuracy: 0.4976 - val_loss: 1.8758 - val_accuracy: 0.4430\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6340 - accuracy: 0.4975 - val_loss: 1.8710 - val_accuracy: 0.4414\n",
      "accuracy:  0.50342857837677\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7472 - accuracy: 0.1682 - val_loss: 2.4545 - val_accuracy: 0.2533\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4569 - accuracy: 0.2414 - val_loss: 2.3295 - val_accuracy: 0.2914\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3391 - accuracy: 0.2788 - val_loss: 2.2752 - val_accuracy: 0.3187\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2636 - accuracy: 0.3025 - val_loss: 2.2331 - val_accuracy: 0.3200\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.1957 - accuracy: 0.3247 - val_loss: 2.1899 - val_accuracy: 0.3346\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1544 - accuracy: 0.3308 - val_loss: 2.1631 - val_accuracy: 0.3476\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1062 - accuracy: 0.3479 - val_loss: 2.1247 - val_accuracy: 0.3541\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0717 - accuracy: 0.3564 - val_loss: 2.1098 - val_accuracy: 0.3603\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0259 - accuracy: 0.3704 - val_loss: 2.0767 - val_accuracy: 0.3675\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0024 - accuracy: 0.3773 - val_loss: 2.0710 - val_accuracy: 0.3717\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9706 - accuracy: 0.3928 - val_loss: 2.0473 - val_accuracy: 0.3887\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9491 - accuracy: 0.3940 - val_loss: 2.0327 - val_accuracy: 0.3840\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9247 - accuracy: 0.4063 - val_loss: 2.0214 - val_accuracy: 0.3924\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9142 - accuracy: 0.4049 - val_loss: 2.0169 - val_accuracy: 0.3905\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.8920 - accuracy: 0.4155 - val_loss: 1.9982 - val_accuracy: 0.3979\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8662 - accuracy: 0.4218 - val_loss: 1.9931 - val_accuracy: 0.4041\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8459 - accuracy: 0.4296 - val_loss: 1.9901 - val_accuracy: 0.4025\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8348 - accuracy: 0.4306 - val_loss: 1.9763 - val_accuracy: 0.4041\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8350 - accuracy: 0.4317 - val_loss: 1.9682 - val_accuracy: 0.4089\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8189 - accuracy: 0.4371 - val_loss: 1.9679 - val_accuracy: 0.4089\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8079 - accuracy: 0.4403 - val_loss: 1.9614 - val_accuracy: 0.4084\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.7838 - accuracy: 0.4472 - val_loss: 1.9646 - val_accuracy: 0.4097\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7683 - accuracy: 0.4531 - val_loss: 1.9423 - val_accuracy: 0.4162\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7680 - accuracy: 0.4496 - val_loss: 1.9421 - val_accuracy: 0.4206\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7603 - accuracy: 0.4550 - val_loss: 1.9393 - val_accuracy: 0.4200\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7594 - accuracy: 0.4584 - val_loss: 1.9360 - val_accuracy: 0.4243\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7363 - accuracy: 0.4646 - val_loss: 1.9337 - val_accuracy: 0.4217\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7327 - accuracy: 0.4637 - val_loss: 1.9219 - val_accuracy: 0.4251\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7177 - accuracy: 0.4639 - val_loss: 1.9235 - val_accuracy: 0.4230\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7160 - accuracy: 0.4698 - val_loss: 1.9192 - val_accuracy: 0.4298\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7221 - accuracy: 0.4717 - val_loss: 1.9223 - val_accuracy: 0.4346\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7039 - accuracy: 0.4733 - val_loss: 1.9178 - val_accuracy: 0.4333\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.6989 - accuracy: 0.4736 - val_loss: 1.9027 - val_accuracy: 0.4392\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.6912 - accuracy: 0.4794 - val_loss: 1.9077 - val_accuracy: 0.4360\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.6903 - accuracy: 0.4808 - val_loss: 1.9073 - val_accuracy: 0.4352\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.6788 - accuracy: 0.4806 - val_loss: 1.8982 - val_accuracy: 0.4383\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6784 - accuracy: 0.4807 - val_loss: 1.8917 - val_accuracy: 0.4383\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6673 - accuracy: 0.4804 - val_loss: 1.9057 - val_accuracy: 0.4398\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6560 - accuracy: 0.4927 - val_loss: 1.8873 - val_accuracy: 0.4371\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6622 - accuracy: 0.4894 - val_loss: 1.9038 - val_accuracy: 0.4384\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6513 - accuracy: 0.4933 - val_loss: 1.8961 - val_accuracy: 0.4390\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6567 - accuracy: 0.4892 - val_loss: 1.8832 - val_accuracy: 0.4427\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6467 - accuracy: 0.4929 - val_loss: 1.8780 - val_accuracy: 0.4459\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6472 - accuracy: 0.4942 - val_loss: 1.8915 - val_accuracy: 0.4503\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6332 - accuracy: 0.4996 - val_loss: 1.8793 - val_accuracy: 0.4457\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6212 - accuracy: 0.5013 - val_loss: 1.8865 - val_accuracy: 0.4471\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6286 - accuracy: 0.4981 - val_loss: 1.8885 - val_accuracy: 0.4470\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6226 - accuracy: 0.4967 - val_loss: 1.8839 - val_accuracy: 0.4449\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6211 - accuracy: 0.5030 - val_loss: 1.8690 - val_accuracy: 0.4500\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6180 - accuracy: 0.5067 - val_loss: 1.8699 - val_accuracy: 0.4490\n",
      "accuracy:  0.4942857027053833\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7469 - accuracy: 0.1684 - val_loss: 2.4859 - val_accuracy: 0.2581\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4589 - accuracy: 0.2437 - val_loss: 2.3353 - val_accuracy: 0.2929\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3375 - accuracy: 0.2807 - val_loss: 2.2553 - val_accuracy: 0.3183\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2594 - accuracy: 0.3015 - val_loss: 2.2190 - val_accuracy: 0.3305\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.1982 - accuracy: 0.3216 - val_loss: 2.1881 - val_accuracy: 0.3416\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1497 - accuracy: 0.3349 - val_loss: 2.1537 - val_accuracy: 0.3490\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1091 - accuracy: 0.3475 - val_loss: 2.1303 - val_accuracy: 0.3610\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0641 - accuracy: 0.3613 - val_loss: 2.1067 - val_accuracy: 0.3614\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0344 - accuracy: 0.3702 - val_loss: 2.0876 - val_accuracy: 0.3703\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0020 - accuracy: 0.3778 - val_loss: 2.0673 - val_accuracy: 0.3751\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9794 - accuracy: 0.3847 - val_loss: 2.0618 - val_accuracy: 0.3775\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9534 - accuracy: 0.3949 - val_loss: 2.0368 - val_accuracy: 0.3865\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9274 - accuracy: 0.4015 - val_loss: 2.0340 - val_accuracy: 0.3927\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9135 - accuracy: 0.4070 - val_loss: 2.0180 - val_accuracy: 0.3932\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.8847 - accuracy: 0.4120 - val_loss: 2.0022 - val_accuracy: 0.3970\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8698 - accuracy: 0.4210 - val_loss: 2.0032 - val_accuracy: 0.3911\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8542 - accuracy: 0.4257 - val_loss: 1.9855 - val_accuracy: 0.4011\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8399 - accuracy: 0.4306 - val_loss: 1.9831 - val_accuracy: 0.4043\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8231 - accuracy: 0.4362 - val_loss: 1.9772 - val_accuracy: 0.4006\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8194 - accuracy: 0.4367 - val_loss: 1.9622 - val_accuracy: 0.4159\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.7951 - accuracy: 0.4419 - val_loss: 1.9656 - val_accuracy: 0.4071\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.7880 - accuracy: 0.4470 - val_loss: 1.9693 - val_accuracy: 0.4067\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7783 - accuracy: 0.4471 - val_loss: 1.9669 - val_accuracy: 0.4086\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7593 - accuracy: 0.4551 - val_loss: 1.9538 - val_accuracy: 0.4162\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7501 - accuracy: 0.4575 - val_loss: 1.9414 - val_accuracy: 0.4192\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7435 - accuracy: 0.4581 - val_loss: 1.9491 - val_accuracy: 0.4108\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7302 - accuracy: 0.4662 - val_loss: 1.9420 - val_accuracy: 0.4173\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7167 - accuracy: 0.4674 - val_loss: 1.9385 - val_accuracy: 0.4230\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7198 - accuracy: 0.4701 - val_loss: 1.9275 - val_accuracy: 0.4302\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7053 - accuracy: 0.4696 - val_loss: 1.9357 - val_accuracy: 0.4289\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7021 - accuracy: 0.4742 - val_loss: 1.9259 - val_accuracy: 0.4238\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7068 - accuracy: 0.4685 - val_loss: 1.9287 - val_accuracy: 0.4224\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.6932 - accuracy: 0.4784 - val_loss: 1.9234 - val_accuracy: 0.4275\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.6747 - accuracy: 0.4794 - val_loss: 1.9257 - val_accuracy: 0.4252\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.6823 - accuracy: 0.4789 - val_loss: 1.9159 - val_accuracy: 0.4270\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.6726 - accuracy: 0.4825 - val_loss: 1.9116 - val_accuracy: 0.4311\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6685 - accuracy: 0.4846 - val_loss: 1.9121 - val_accuracy: 0.4260\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6602 - accuracy: 0.4868 - val_loss: 1.9051 - val_accuracy: 0.4308\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6479 - accuracy: 0.4941 - val_loss: 1.9092 - val_accuracy: 0.4325\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6530 - accuracy: 0.4883 - val_loss: 1.9120 - val_accuracy: 0.4298\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6461 - accuracy: 0.4906 - val_loss: 1.9084 - val_accuracy: 0.4384\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6344 - accuracy: 0.4961 - val_loss: 1.8950 - val_accuracy: 0.4425\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6290 - accuracy: 0.4956 - val_loss: 1.8879 - val_accuracy: 0.4416\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6366 - accuracy: 0.4949 - val_loss: 1.8936 - val_accuracy: 0.4384\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6291 - accuracy: 0.4956 - val_loss: 1.9010 - val_accuracy: 0.4416\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6252 - accuracy: 0.4984 - val_loss: 1.8890 - val_accuracy: 0.4394\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6159 - accuracy: 0.4994 - val_loss: 1.8812 - val_accuracy: 0.4413\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6154 - accuracy: 0.5016 - val_loss: 1.8877 - val_accuracy: 0.4438\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6103 - accuracy: 0.5028 - val_loss: 1.8881 - val_accuracy: 0.4441\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.5935 - accuracy: 0.5090 - val_loss: 1.8799 - val_accuracy: 0.4451\n",
      "accuracy:  0.46000000834465027\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7483 - accuracy: 0.1664 - val_loss: 2.4774 - val_accuracy: 0.2521\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4569 - accuracy: 0.2428 - val_loss: 2.3554 - val_accuracy: 0.2916\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3440 - accuracy: 0.2790 - val_loss: 2.2897 - val_accuracy: 0.3094\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2633 - accuracy: 0.2952 - val_loss: 2.2328 - val_accuracy: 0.3190\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2008 - accuracy: 0.3212 - val_loss: 2.2006 - val_accuracy: 0.3379\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1428 - accuracy: 0.3386 - val_loss: 2.1564 - val_accuracy: 0.3465\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1034 - accuracy: 0.3471 - val_loss: 2.1330 - val_accuracy: 0.3581\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0662 - accuracy: 0.3619 - val_loss: 2.1180 - val_accuracy: 0.3619\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0203 - accuracy: 0.3700 - val_loss: 2.0823 - val_accuracy: 0.3751\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 1.9950 - accuracy: 0.3810 - val_loss: 2.0747 - val_accuracy: 0.3729\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9807 - accuracy: 0.3845 - val_loss: 2.0611 - val_accuracy: 0.3841\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9428 - accuracy: 0.3984 - val_loss: 2.0411 - val_accuracy: 0.3871\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9249 - accuracy: 0.4051 - val_loss: 2.0402 - val_accuracy: 0.3898\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.8953 - accuracy: 0.4106 - val_loss: 2.0185 - val_accuracy: 0.3962\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.8683 - accuracy: 0.4194 - val_loss: 2.0160 - val_accuracy: 0.3951\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8567 - accuracy: 0.4236 - val_loss: 1.9907 - val_accuracy: 0.4025\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8419 - accuracy: 0.4269 - val_loss: 1.9952 - val_accuracy: 0.4105\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8270 - accuracy: 0.4338 - val_loss: 1.9791 - val_accuracy: 0.4106\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8269 - accuracy: 0.4376 - val_loss: 1.9811 - val_accuracy: 0.4163\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8011 - accuracy: 0.4415 - val_loss: 1.9784 - val_accuracy: 0.4129\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.8032 - accuracy: 0.4377 - val_loss: 1.9773 - val_accuracy: 0.4130\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.7796 - accuracy: 0.4449 - val_loss: 1.9630 - val_accuracy: 0.4124\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7689 - accuracy: 0.4513 - val_loss: 1.9664 - val_accuracy: 0.4111\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7538 - accuracy: 0.4558 - val_loss: 1.9570 - val_accuracy: 0.4189\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7580 - accuracy: 0.4544 - val_loss: 1.9462 - val_accuracy: 0.4163\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7304 - accuracy: 0.4618 - val_loss: 1.9402 - val_accuracy: 0.4176\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7323 - accuracy: 0.4645 - val_loss: 1.9344 - val_accuracy: 0.4249\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7327 - accuracy: 0.4630 - val_loss: 1.9445 - val_accuracy: 0.4232\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7257 - accuracy: 0.4673 - val_loss: 1.9410 - val_accuracy: 0.4240\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7083 - accuracy: 0.4706 - val_loss: 1.9403 - val_accuracy: 0.4244\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.7003 - accuracy: 0.4760 - val_loss: 1.9349 - val_accuracy: 0.4194\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7010 - accuracy: 0.4725 - val_loss: 1.9357 - val_accuracy: 0.4232\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.6906 - accuracy: 0.4764 - val_loss: 1.9362 - val_accuracy: 0.4237\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.6839 - accuracy: 0.4783 - val_loss: 1.9212 - val_accuracy: 0.4303\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.6595 - accuracy: 0.4849 - val_loss: 1.9232 - val_accuracy: 0.4298\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.6711 - accuracy: 0.4808 - val_loss: 1.9284 - val_accuracy: 0.4363\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6626 - accuracy: 0.4869 - val_loss: 1.9250 - val_accuracy: 0.4329\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6573 - accuracy: 0.4849 - val_loss: 1.9218 - val_accuracy: 0.4344\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6536 - accuracy: 0.4901 - val_loss: 1.9193 - val_accuracy: 0.4359\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6584 - accuracy: 0.4851 - val_loss: 1.9273 - val_accuracy: 0.4305\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6394 - accuracy: 0.4929 - val_loss: 1.9168 - val_accuracy: 0.4289\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6328 - accuracy: 0.4931 - val_loss: 1.9095 - val_accuracy: 0.4322\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6432 - accuracy: 0.4919 - val_loss: 1.9192 - val_accuracy: 0.4294\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6310 - accuracy: 0.4984 - val_loss: 1.9104 - val_accuracy: 0.4370\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6216 - accuracy: 0.4988 - val_loss: 1.9112 - val_accuracy: 0.4284\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6164 - accuracy: 0.5007 - val_loss: 1.9156 - val_accuracy: 0.4346\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6125 - accuracy: 0.5017 - val_loss: 1.9055 - val_accuracy: 0.4341\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6151 - accuracy: 0.4979 - val_loss: 1.9109 - val_accuracy: 0.4387\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.5980 - accuracy: 0.5018 - val_loss: 1.8994 - val_accuracy: 0.4400\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6052 - accuracy: 0.5031 - val_loss: 1.9079 - val_accuracy: 0.4333\n",
      "accuracy:  0.4585714340209961\n",
      "Epoch 1/50\n",
      "788/788 - 2s - loss: 2.7459 - accuracy: 0.1677 - val_loss: 2.4707 - val_accuracy: 0.2549\n",
      "Epoch 2/50\n",
      "788/788 - 2s - loss: 2.4578 - accuracy: 0.2457 - val_loss: 2.3459 - val_accuracy: 0.2875\n",
      "Epoch 3/50\n",
      "788/788 - 2s - loss: 2.3489 - accuracy: 0.2710 - val_loss: 2.2676 - val_accuracy: 0.3111\n",
      "Epoch 4/50\n",
      "788/788 - 2s - loss: 2.2723 - accuracy: 0.2986 - val_loss: 2.2293 - val_accuracy: 0.3246\n",
      "Epoch 5/50\n",
      "788/788 - 2s - loss: 2.2023 - accuracy: 0.3187 - val_loss: 2.1800 - val_accuracy: 0.3316\n",
      "Epoch 6/50\n",
      "788/788 - 2s - loss: 2.1516 - accuracy: 0.3298 - val_loss: 2.1529 - val_accuracy: 0.3471\n",
      "Epoch 7/50\n",
      "788/788 - 2s - loss: 2.1039 - accuracy: 0.3491 - val_loss: 2.1252 - val_accuracy: 0.3603\n",
      "Epoch 8/50\n",
      "788/788 - 2s - loss: 2.0624 - accuracy: 0.3619 - val_loss: 2.0922 - val_accuracy: 0.3684\n",
      "Epoch 9/50\n",
      "788/788 - 2s - loss: 2.0379 - accuracy: 0.3688 - val_loss: 2.0743 - val_accuracy: 0.3786\n",
      "Epoch 10/50\n",
      "788/788 - 2s - loss: 2.0071 - accuracy: 0.3789 - val_loss: 2.0724 - val_accuracy: 0.3830\n",
      "Epoch 11/50\n",
      "788/788 - 2s - loss: 1.9709 - accuracy: 0.3925 - val_loss: 2.0581 - val_accuracy: 0.3868\n",
      "Epoch 12/50\n",
      "788/788 - 2s - loss: 1.9497 - accuracy: 0.3954 - val_loss: 2.0352 - val_accuracy: 0.3887\n",
      "Epoch 13/50\n",
      "788/788 - 2s - loss: 1.9293 - accuracy: 0.4027 - val_loss: 2.0151 - val_accuracy: 0.4013\n",
      "Epoch 14/50\n",
      "788/788 - 2s - loss: 1.9045 - accuracy: 0.4114 - val_loss: 2.0149 - val_accuracy: 0.4040\n",
      "Epoch 15/50\n",
      "788/788 - 2s - loss: 1.8763 - accuracy: 0.4196 - val_loss: 1.9947 - val_accuracy: 0.4030\n",
      "Epoch 16/50\n",
      "788/788 - 2s - loss: 1.8702 - accuracy: 0.4184 - val_loss: 1.9858 - val_accuracy: 0.4138\n",
      "Epoch 17/50\n",
      "788/788 - 2s - loss: 1.8573 - accuracy: 0.4264 - val_loss: 1.9888 - val_accuracy: 0.4081\n",
      "Epoch 18/50\n",
      "788/788 - 2s - loss: 1.8237 - accuracy: 0.4363 - val_loss: 1.9709 - val_accuracy: 0.4154\n",
      "Epoch 19/50\n",
      "788/788 - 2s - loss: 1.8235 - accuracy: 0.4342 - val_loss: 1.9472 - val_accuracy: 0.4233\n",
      "Epoch 20/50\n",
      "788/788 - 2s - loss: 1.8047 - accuracy: 0.4398 - val_loss: 1.9422 - val_accuracy: 0.4229\n",
      "Epoch 21/50\n",
      "788/788 - 2s - loss: 1.7875 - accuracy: 0.4454 - val_loss: 1.9503 - val_accuracy: 0.4230\n",
      "Epoch 22/50\n",
      "788/788 - 2s - loss: 1.7747 - accuracy: 0.4482 - val_loss: 1.9392 - val_accuracy: 0.4302\n",
      "Epoch 23/50\n",
      "788/788 - 2s - loss: 1.7749 - accuracy: 0.4481 - val_loss: 1.9302 - val_accuracy: 0.4271\n",
      "Epoch 24/50\n",
      "788/788 - 2s - loss: 1.7574 - accuracy: 0.4547 - val_loss: 1.9304 - val_accuracy: 0.4327\n",
      "Epoch 25/50\n",
      "788/788 - 2s - loss: 1.7489 - accuracy: 0.4568 - val_loss: 1.9233 - val_accuracy: 0.4340\n",
      "Epoch 26/50\n",
      "788/788 - 2s - loss: 1.7347 - accuracy: 0.4632 - val_loss: 1.9192 - val_accuracy: 0.4378\n",
      "Epoch 27/50\n",
      "788/788 - 2s - loss: 1.7274 - accuracy: 0.4703 - val_loss: 1.9133 - val_accuracy: 0.4371\n",
      "Epoch 28/50\n",
      "788/788 - 2s - loss: 1.7332 - accuracy: 0.4623 - val_loss: 1.9021 - val_accuracy: 0.4429\n",
      "Epoch 29/50\n",
      "788/788 - 2s - loss: 1.7211 - accuracy: 0.4689 - val_loss: 1.9146 - val_accuracy: 0.4444\n",
      "Epoch 30/50\n",
      "788/788 - 2s - loss: 1.7145 - accuracy: 0.4659 - val_loss: 1.8946 - val_accuracy: 0.4448\n",
      "Epoch 31/50\n",
      "788/788 - 2s - loss: 1.6937 - accuracy: 0.4746 - val_loss: 1.8962 - val_accuracy: 0.4492\n",
      "Epoch 32/50\n",
      "788/788 - 2s - loss: 1.7011 - accuracy: 0.4703 - val_loss: 1.9088 - val_accuracy: 0.4425\n",
      "Epoch 33/50\n",
      "788/788 - 2s - loss: 1.6911 - accuracy: 0.4757 - val_loss: 1.8873 - val_accuracy: 0.4522\n",
      "Epoch 34/50\n",
      "788/788 - 2s - loss: 1.6912 - accuracy: 0.4798 - val_loss: 1.8966 - val_accuracy: 0.4425\n",
      "Epoch 35/50\n",
      "788/788 - 2s - loss: 1.6791 - accuracy: 0.4821 - val_loss: 1.8936 - val_accuracy: 0.4483\n",
      "Epoch 36/50\n",
      "788/788 - 2s - loss: 1.6585 - accuracy: 0.4855 - val_loss: 1.8781 - val_accuracy: 0.4508\n",
      "Epoch 37/50\n",
      "788/788 - 2s - loss: 1.6565 - accuracy: 0.4830 - val_loss: 1.8841 - val_accuracy: 0.4568\n",
      "Epoch 38/50\n",
      "788/788 - 2s - loss: 1.6494 - accuracy: 0.4867 - val_loss: 1.8782 - val_accuracy: 0.4495\n",
      "Epoch 39/50\n",
      "788/788 - 2s - loss: 1.6464 - accuracy: 0.4927 - val_loss: 1.8751 - val_accuracy: 0.4517\n",
      "Epoch 40/50\n",
      "788/788 - 2s - loss: 1.6452 - accuracy: 0.4921 - val_loss: 1.8745 - val_accuracy: 0.4467\n",
      "Epoch 41/50\n",
      "788/788 - 2s - loss: 1.6373 - accuracy: 0.4922 - val_loss: 1.8754 - val_accuracy: 0.4473\n",
      "Epoch 42/50\n",
      "788/788 - 2s - loss: 1.6274 - accuracy: 0.4963 - val_loss: 1.8690 - val_accuracy: 0.4554\n",
      "Epoch 43/50\n",
      "788/788 - 2s - loss: 1.6349 - accuracy: 0.4967 - val_loss: 1.8669 - val_accuracy: 0.4613\n",
      "Epoch 44/50\n",
      "788/788 - 2s - loss: 1.6266 - accuracy: 0.4931 - val_loss: 1.8766 - val_accuracy: 0.4484\n",
      "Epoch 45/50\n",
      "788/788 - 2s - loss: 1.6287 - accuracy: 0.4937 - val_loss: 1.8644 - val_accuracy: 0.4665\n",
      "Epoch 46/50\n",
      "788/788 - 2s - loss: 1.6205 - accuracy: 0.4964 - val_loss: 1.8713 - val_accuracy: 0.4579\n",
      "Epoch 47/50\n",
      "788/788 - 2s - loss: 1.6109 - accuracy: 0.5002 - val_loss: 1.8589 - val_accuracy: 0.4629\n",
      "Epoch 48/50\n",
      "788/788 - 2s - loss: 1.6181 - accuracy: 0.5051 - val_loss: 1.8579 - val_accuracy: 0.4635\n",
      "Epoch 49/50\n",
      "788/788 - 2s - loss: 1.6088 - accuracy: 0.5020 - val_loss: 1.8482 - val_accuracy: 0.4627\n",
      "Epoch 50/50\n",
      "788/788 - 2s - loss: 1.6076 - accuracy: 0.5035 - val_loss: 1.8622 - val_accuracy: 0.4630\n",
      "accuracy:  0.43142858147621155\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.datasets import cifar100\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import numpy as np\n",
    "\n",
    "def run_MLP_model(training_data, training_labels, testing_data, testing_labels, first_activation_function, second_activation_function, num_hidden_units, learning_rate, optimiser, decay_level, momentum, epochs, loss_function):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(num_hidden_units, activation=first_activation_function, input_dim=training_data.shape[1]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_hidden_units, activation=first_activation_function))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20, activation=second_activation_function))\n",
    "\n",
    "    if (optimiser == 'SGD'):\n",
    "        op = SGD(lr=learning_rate, decay=decay_level, momentum=momentum, nesterov=True)\n",
    "\n",
    "    else:\n",
    "        op = Adam(lr=learning_rate, decay=decay_level)\n",
    "\n",
    "    # can also use loss function categorical_crossentropy\n",
    "    # or optimiser SGD\n",
    "    # try with different optimisers and loss functions\n",
    "    model.compile(optimizer=op,\n",
    "                  loss=loss_function,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(training_data, training_labels, epochs=epochs, batch_size=32, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(testing_data, testing_labels, batch_size=128, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "# helper function for concatenating labels onto their corresponding data points\n",
    "def concatenate_data(training_data, training_labels):\n",
    "    return np.column_stack((training_data, training_labels))\n",
    "\n",
    "# data set is randomised and then split in a 70:30 ratio for training:validation sets\n",
    "def split_into_validation_training(training_matrix):\n",
    "    \n",
    "    import random\n",
    "    random.shuffle(training_matrix)\n",
    "\n",
    "    training_set = training_matrix[:int(len(training_matrix)*0.7)]\n",
    "    validation_set = training_matrix[int(len(training_matrix)*0.7):]\n",
    "    \n",
    "    return training_set, validation_set\n",
    "\n",
    "#using 10 fold cross validation here to evaluate the performance of SVM\n",
    "def cross_validation():\n",
    "\n",
    "    (training_data, training_labels), (testing_data, testing_labels) = (cifar100.load_data(\"coarse\"))\n",
    "\n",
    "    momentum = 0.9\n",
    "    decay=1e-06\n",
    "    learning_rate = 0.001\n",
    "    first_activation_function = 'relu'\n",
    "    second_activation_function = 'softmax'\n",
    "    loss = 'sparse_categorical_crossentropy'\n",
    "    optimiser = 'Adam'\n",
    "    epochs = 50\n",
    "    num_hidden_units = 256\n",
    "\n",
    "    # reshape the data \n",
    "    training_data = training_data.reshape(50000, 3072)\n",
    "    testing_data = testing_data.reshape(10000, 3072)\n",
    "\n",
    "    concatenated_training = concatenate_data(training_data, training_labels)\n",
    "\n",
    "    training_set, validation_set = split_into_validation_training(concatenated_training)\n",
    "\n",
    "    training_data = training_set[:, :-1]\n",
    "    training_labels = np.squeeze(training_set[:, -1])\n",
    "\n",
    "    validation_data = validation_set[:, :-1]\n",
    "    validation_labels = np.squeeze(validation_set[:, -1])\n",
    "\n",
    "    training_data = training_data.astype('float32')\n",
    "    testing_data = testing_data.astype('float32')\n",
    "    validation_data = validation_data.astype('float32')\n",
    "\n",
    "    # Centre data\n",
    "    training_data, testing_data = centre_data(training_data, testing_data)\n",
    "\n",
    "    # Apply PCA\n",
    "    training_data, testing_data = PCA(0.9, training_data, testing_data)\n",
    "\n",
    "    number_training_samples = len(training_data)\n",
    "    number_validation_samples = len(validation_data)\n",
    "    number_testing_samples = len(testing_data)\n",
    "\n",
    "    # Reshape data from channel to rows\n",
    "    training_data = np.reshape(training_data, (number_training_samples, -1))\n",
    "    validation_data = np.reshape(validation_data, (number_validation_samples, -1))\n",
    "    testing_data = np.reshape(testing_data, (number_testing_samples, -1))\n",
    "\n",
    "    # Normalization of pixel values (to [0-1] range)\n",
    "    training_data = training_data / 255\n",
    "    testing_data = testing_data / 255\n",
    "    validation_data = validation_data / 255\n",
    "\n",
    "    cv = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in cv.split(training_data):\n",
    "\n",
    "      training_set, training_set_labels = training_data[train_index], training_labels[train_index]\n",
    "      testing_set, testing_set_labels = training_data[test_index], training_labels[test_index]\n",
    "\n",
    "      accuracy= run_MLP_model(training_set, training_set_labels, testing_set, testing_set_labels, first_activation_function, second_activation_function, num_hidden_units, learning_rate, optimiser, decay, momentum, epochs, loss)\n",
    "      print('accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52gJ6_roEDSF"
   },
   "source": [
    "**Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGlmq6J8EFMs",
    "outputId": "cd634afd-4df0-4214-c073-ffa6ad724a5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 22.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.6min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 22.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.5min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.3min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 21.2min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 20.8min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.3614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def flatten_data(x_train, y_train, x_test, y_test):\n",
    "    new_image_shape = 1\n",
    "    for dim in range(1, len(x_train.shape)):\n",
    "        new_image_shape *= x_train.shape[dim]\n",
    "        \n",
    "    flat_x_train = x_train.reshape((x_train.shape[0], new_image_shape))\n",
    "    flat_y_train = np.ravel(y_train)\n",
    "    \n",
    "    flat_x_test = x_test.reshape((x_test.shape[0], new_image_shape))\n",
    "    flat_y_test = np.ravel(y_test)\n",
    "    return flat_x_train, flat_y_train, flat_x_test, flat_y_test\n",
    "\n",
    "def cross_validation():\n",
    "\n",
    "    (training_data, training_labels), (testing_data, testing_labels) = (cifar100.load_data(\"coarse\"))\n",
    "    cv = KFold(n_splits=10)\n",
    "\n",
    "    momentum = 0.9\n",
    "    decay=1e-6\n",
    "    learning_rate = 0.001\n",
    "    first_activation_function = 'relu'\n",
    "    second_activation_function = 'softmax'\n",
    "    loss = 'sparse_categorical_crossentropy'\n",
    "    optimiser = 'Adam'\n",
    "    epochs = 20\n",
    "    num_hidden_units = 256\n",
    "\n",
    "    training_data, training_labels, testing_data, testing_labels= flatten_data(training_data, training_labels, testing_data, testing_labels)\n",
    "\n",
    "    cv = KFold(n_splits=10)\n",
    "\n",
    "    for train_index, test_index in cv.split(training_data):\n",
    "\n",
    "      training_set, training_set_labels = training_data[train_index], training_labels[train_index]\n",
    "      testing_set, testing_set_labels = training_data[test_index], training_labels[test_index]\n",
    "      \n",
    "      model = RandomForestClassifier(\n",
    "      n_jobs=-1, \n",
    "      verbose=1,\n",
    "      n_estimators=400,\n",
    "      bootstrap=False, \n",
    "      max_features='sqrt', \n",
    "      criterion='gini')\n",
    "\n",
    "      model.fit(training_set, training_set_labels)\n",
    "      accuracy= model.score(testing_set, testing_set_labels)\n",
    "      print('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "cross_validation()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cross Validation of the Three Algos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
